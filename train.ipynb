{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e3d9a26-113c-43a6-bf33-98627b1c2316",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "import lpips\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from src import (\n",
    "    Encoder,\n",
    "    Decoder,\n",
    "    NormNoiseQuantization,\n",
    "    AEModel,\n",
    "    GoogleDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcbe4fe8-a2c2-479a-8a1c-cd84e822dda9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cabdf27-9229-49db-bae7-fac24a4487ed",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf568717-04d6-4891-87fc-d81df7c47a6e",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 510, 510]             448\n",
      "         LeakyReLU-2         [-1, 16, 510, 510]               0\n",
      "       BatchNorm2d-3         [-1, 16, 510, 510]              32\n",
      "         Dropout2d-4         [-1, 16, 510, 510]               0\n",
      "         MaxPool2d-5         [-1, 16, 170, 170]               0\n",
      "            Conv2d-6         [-1, 32, 168, 168]           4,640\n",
      "         LeakyReLU-7         [-1, 32, 168, 168]               0\n",
      "       BatchNorm2d-8         [-1, 32, 168, 168]              64\n",
      "         Dropout2d-9         [-1, 32, 168, 168]               0\n",
      "        MaxPool2d-10           [-1, 32, 56, 56]               0\n",
      "           Conv2d-11           [-1, 64, 52, 52]          51,264\n",
      "        LeakyReLU-12           [-1, 64, 52, 52]               0\n",
      "      BatchNorm2d-13           [-1, 64, 52, 52]             128\n",
      "        Dropout2d-14           [-1, 64, 52, 52]               0\n",
      "        MaxPool2d-15           [-1, 64, 17, 17]               0\n",
      "           Conv2d-16          [-1, 128, 13, 13]         204,928\n",
      "        LeakyReLU-17          [-1, 128, 13, 13]               0\n",
      "      BatchNorm2d-18          [-1, 128, 13, 13]             256\n",
      "        Dropout2d-19          [-1, 128, 13, 13]               0\n",
      "        MaxPool2d-20            [-1, 128, 4, 4]               0\n",
      "           Conv2d-21            [-1, 256, 1, 1]         524,544\n",
      "        LeakyReLU-22            [-1, 256, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 786,304\n",
      "Trainable params: 786,304\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 164.96\n",
      "Params size (MB): 3.00\n",
      "Estimated Total Size (MB): 170.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Encoder()\n",
    "summary(model, (3, 512, 512), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a13afe-f906-4172-a8b4-460fac6db487",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 128, 2, 2]         131,200\n",
      "              GELU-2            [-1, 128, 2, 2]               0\n",
      "       BatchNorm2d-3            [-1, 128, 2, 2]             256\n",
      "   ConvTranspose2d-4             [-1, 64, 4, 4]          73,792\n",
      "              GELU-5             [-1, 64, 4, 4]               0\n",
      "       BatchNorm2d-6             [-1, 64, 4, 4]             128\n",
      "UpsamplingBilinear2d-7           [-1, 64, 16, 16]               0\n",
      "   ConvTranspose2d-8           [-1, 64, 16, 16]          36,928\n",
      "              GELU-9           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-10           [-1, 64, 16, 16]             128\n",
      "UpsamplingBilinear2d-11           [-1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-12           [-1, 32, 64, 64]          18,464\n",
      "             GELU-13           [-1, 32, 64, 64]               0\n",
      "      BatchNorm2d-14           [-1, 32, 64, 64]              64\n",
      "UpsamplingBilinear2d-15         [-1, 32, 256, 256]               0\n",
      "  ConvTranspose2d-16         [-1, 16, 256, 256]           4,624\n",
      "             GELU-17         [-1, 16, 256, 256]               0\n",
      "      BatchNorm2d-18         [-1, 16, 256, 256]              32\n",
      "UpsamplingBilinear2d-19         [-1, 16, 512, 512]               0\n",
      "  ConvTranspose2d-20          [-1, 3, 512, 512]             435\n",
      "             GELU-21          [-1, 3, 512, 512]               0\n",
      "      BatchNorm2d-22          [-1, 3, 512, 512]               6\n",
      "================================================================\n",
      "Total params: 266,057\n",
      "Trainable params: 266,057\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 95.54\n",
      "Params size (MB): 1.01\n",
      "Estimated Total Size (MB): 96.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Decoder()\n",
    "summary(model, (256, 1, 1), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ca7bc-bb94-43b3-a0d1-c200e2f7426d",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c344b119-5b5b-430f-9398-255193a98d59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MSE\n",
    "def mse_loss(result, target):\n",
    "    return F.mse_loss(result, target)\n",
    "\n",
    "# PSNR\n",
    "def psnr(result, target):\n",
    "    mse = mse_loss(result, target)\n",
    "    return 10 * torch.log10(1 / mse) * (torch.max(result) ** 2)\n",
    "\n",
    "# Intermediate vector entropy\n",
    "def latent_entropy_aprox(result):\n",
    "    probabilities = F.softmax(result, dim=1)\n",
    "    entropy = F.cross_entropy(probabilities, torch.ones_like(probabilities) / probabilities.size(1))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def normalize_img(img: torch.Tensor) -> torch.Tensor:\n",
    "    img -= img.min()\n",
    "    img /= img.max()\n",
    "    # img *= 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6935ab1-b98c-4a47-9b90-b4005661186d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb3dd41d-d95e-475b-9ccf-cd6043a2f7a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = '/data/ucheba/master_2sem/archive/'\n",
    "ds = GoogleDataset(csv_file=d + 'train.csv', image_dir=d, batch_size=6)\n",
    "\n",
    "indices = list(range(len(ds)))\n",
    "np.random.shuffle(indices)\n",
    "split_ix = int(0.9*len(ds))\n",
    "train_indices, val_indices = indices[:split_ix], indices[split_ix:]\n",
    "train_sampler = sampler.SubsetRandomSampler(train_indices)\n",
    "test_sampler = sampler.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train = DataLoader(ds, batch_size=ds.batch_size, num_workers=8, sampler=train_sampler)\n",
    "test = DataLoader(ds, batch_size=ds.batch_size, num_workers=8, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c154b176-7ead-4d38-89dd-8880dcef2c9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "quantizator = NormNoiseQuantization()\n",
    "loss_fn_alex = lpips.LPIPS(net='alex', verbose=False)\n",
    "loss_fn_alex.to(device)\n",
    "\n",
    "\n",
    "model = AEModel()#.to(device)\n",
    "model.load_state_dict(torch.load(open('./weights/ae_step58200.pt', 'rb'), map_location=device))\n",
    "model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "writer = SummaryWriter(logdir='runs/Jun24_01-39-04_mi/')\n",
    "train_step = 8775 + 56238\n",
    "test_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbdd384-d4a3-4452-8def-901c79b05ac0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19880/19880 [3:37:21<00:00,  1.52it/s]  \n",
      " 66%|██████▌   | 13129/19880 [2:23:32<1:17:31,  1.45it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    losses = defaultdict(lambda: [])\n",
    "    \n",
    "    for batch in tqdm(train, total=len(train)):\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        state = model.encode(batch)\n",
    "        quantized = quantizator(state)\n",
    "        pred = model.decode(quantized)\n",
    "        \n",
    "        loss_mse = mse_loss(pred, batch)\n",
    "        loss_content = loss_fn_alex((pred), (batch)).mean()\n",
    "        \n",
    "        loss = loss_mse + loss_content\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss_psnr = psnr(pred, batch)\n",
    "            loss_entropy = latent_entropy_aprox(quantized)\n",
    "\n",
    "            writer.add_scalar('train/mse', loss_mse.item(), train_step)\n",
    "            writer.add_scalar('train/psnr', loss_psnr.item(), train_step)\n",
    "            writer.add_scalar('train/entropy', loss_entropy.item(), train_step)\n",
    "            writer.add_scalar('train/conent_loss', loss_content.item(), train_step)\n",
    "            writer.add_scalar('train/loss', loss.item(), train_step)\n",
    "            if train_step % 10 == 0:\n",
    "                writer.add_image('train/pred', normalize_img(pred[0]), train_step)\n",
    "                writer.add_image('train/target', normalize_img(batch[0]), train_step)\n",
    "\n",
    "            if train_step % 5000 == 0:\n",
    "                model.cpu()\n",
    "                torch.save(model.state_dict(), f'weights/ae_step{train_step}.pt')\n",
    "                model.to(device)\n",
    "            train_step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f16ba7-85d2-4ccf-83b6-ffdf1a4d19f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1887094-b9b4-4b5a-8536-5671c3f07db2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}